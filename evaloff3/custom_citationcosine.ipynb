{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_SET_PATH = './data/aan_full.json'\n",
    "TEST_SET_PATH = './data/aan_test.json'\n",
    "OUTPUT_PATH = './results/custom_citationcosine_aan.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_SET_PATH = './data/dblp_full.json'\n",
    "TEST_SET_PATH = './data/dblp_test.json'\n",
    "OUTPUT_PATH = './results/custom_citationcosine_dblp.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FULL_SET_PATH) as f:\n",
    "    full_set = json.load(f)\n",
    "    \n",
    "full_set_dict = dict([(paper['id'], paper) for paper in full_set])\n",
    "paper_ids = [paper['id'] for paper in full_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_SET_PATH) as f:\n",
    "    test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_citation_cosine_similarity(paper_set1, paper_set2):\n",
    "    intersection = paper_set1.intersection(paper_set2)\n",
    "    degree_geometric_mean = (len(paper_set1) * len(paper_set2)) ** 0.5\n",
    "    \n",
    "    return len(intersection) / degree_geometric_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing compute_citation_cosine_similarity\n",
    "paper_set1 = {'paper1', 'paper2', 'paper3'}\n",
    "paper_set2 = {'paper1', 'paper2', 'paper3'}\n",
    "\n",
    "compute_citation_cosine_similarity(paper_set1, paper_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cc4bc2da9a4357a4f634d44f5a428f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_score_tuples_list = []\n",
    "for input_papers in tqdm(test_set):\n",
    "    candidate_score_tuples = []\n",
    "    input_ref_cit_set = set()\n",
    "    for input_paper in input_papers:\n",
    "        input_ref_cit_set.update(input_paper['references'] + input_paper['citations'])\n",
    "    \n",
    "    for paper in full_set:\n",
    "        cosine_similarity = compute_citation_cosine_similarity(input_ref_cit_set, set(paper['references'] + paper['citations']))\n",
    "        candidate_score_tuples.append((paper['id'], cosine_similarity))\n",
    "        \n",
    "    candidate_score_tuples_list.append(candidate_score_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_score_tuples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22726"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_score_tuples_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6468916', 0.0),\n",
       " ('12824513', 0.0),\n",
       " ('16066432', 0.0),\n",
       " ('19790595', 0.0),\n",
       " ('20948110', 0.0),\n",
       " ('22861983', 0.0),\n",
       " ('24640360', 0.0),\n",
       " ('24836904', 0.0),\n",
       " ('28988658', 0.0),\n",
       " ('34559920', 0.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_score_tuples_list[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7425481c760340caad7a5fdab401d96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for candidate_scores, input_papers in tqdm(zip(candidate_score_tuples_list, test_set)):\n",
    "    result = {}\n",
    "    result['input'] = [input_paper['id'] for input_paper in input_papers]\n",
    "    input_paper_ids_set = set(result['input'])\n",
    "    \n",
    "    candidate_scores.sort(key=lambda x: x[1], reverse=True)    \n",
    "    filtered_candidate_scores = [cs for cs in candidate_scores if cs[0] not in input_paper_ids_set]\n",
    "    \n",
    "    result['output'] = [cs[0] for cs in filtered_candidate_scores[:100]]\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2951755740', 0.8459824315609656),\n",
       " ('2606987267', 0.6340037731068526),\n",
       " ('2624503621', 0.4983184185907058),\n",
       " ('2950642167', 0.3549711258126779),\n",
       " ('2556802233', 0.2993924754260479),\n",
       " ('2560609797', 0.27517203630084297),\n",
       " ('2792096654', 0.26403934479377983),\n",
       " ('2793173694', 0.2619684159977919),\n",
       " ('2769473888', 0.25332019855244947),\n",
       " ('2989599677', 0.24715576637149037)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_score_tuples_list[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
