{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data into ElasticSearch : experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=Elasticsearch([{'host':'localhost', 'port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='dblp_v12_v2_test', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'dblp_v12_v2_test'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "}\n",
    "\n",
    "es.indices.create(index='dblp_v12_v2_test', ignore=[400, 404], body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22726"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "with open('./datasets/preprocessed_dblp_v12_subset.json') as file:\n",
    "    test_set = json.load(file)\n",
    "    \n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d074bdf036c484fbaa06433226eb8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22726.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# uploading to elasticsearch\n",
    "bulk = []\n",
    "for paper in tqdm(test_set):\n",
    "    formatted_paper = {} \n",
    "    formatted_paper['paper_id'] = paper['id']\n",
    "    formatted_paper['title'] = paper['title']\n",
    "    formatted_paper['abstract'] = paper['abstract']\n",
    "    formatted_paper['references'] = paper['references']\n",
    "    formatted_paper['citations'] = paper['citations']\n",
    "    formatted_paper['fos'] = paper['fos']\n",
    "    formatted_paper['linked_papers'] = list(set(paper['references'] + paper['citations']))\n",
    "    \n",
    "    bulk.append(formatted_paper)\n",
    "    \n",
    "    if len(bulk) > 5000:\n",
    "        helpers.bulk(es, bulk, index='dblp_v12_v2_test', doc_type='paper')\n",
    "        bulk = []\n",
    "        \n",
    "if papers_bulk:\n",
    "    helpers.bulk(es, bulk, index='dblp_v12_v2_test', doc_type='paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data into ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./datasets/dblp-aminer_v12/dblp.v12.json\"\n",
    "N_RECORDS = 4894081\n",
    "INDEX_NAME = \"dblp_v12_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93d56f0e0b14235ad82c7d19bf7883b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4894081.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a20124d33024ad1a34cd3c52a48931b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4894081.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4894081"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_cit_dict = {}\n",
    "\n",
    "# adding papers with at least 1 citation\n",
    "with open(DATASET_PATH) as file:\n",
    "    file.readline() # skip first line\n",
    "    \n",
    "    for _ in tqdm(range(N_RECORDS)):\n",
    "        line = file.readline()\n",
    "        try:\n",
    "            paper = json.loads(line[1:])\n",
    "        except:\n",
    "            paper = json.loads(line)\n",
    "        \n",
    "        if 'references' in paper:\n",
    "            for ref_id in paper['references']:\n",
    "                if ref_id in paper_cit_dict:\n",
    "                    paper_cit_dict[ref_id].append(paper['id'])\n",
    "                else:\n",
    "                    paper_cit_dict[ref_id] = [paper['id']]\n",
    "\n",
    "# adding papers with no citation\n",
    "with open(DATASET_PATH) as file:\n",
    "    file.readline() # skip first line\n",
    "    \n",
    "    for _ in tqdm(range(N_RECORDS)):\n",
    "        line = file.readline()\n",
    "        try:\n",
    "            paper = json.loads(line[1:])\n",
    "        except:\n",
    "            paper = json.loads(line)\n",
    "        \n",
    "        if paper['id'] not in paper_cit_dict:\n",
    "            paper_cit_dict[paper['id']] = []\n",
    "\n",
    "len(paper_cit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_cit_dict_p1 = dict(list(paper_cit_dict.items())[:len(paper_cit_dict)//2])\n",
    "paper_cit_dict_p2 = dict(list(paper_cit_dict.items())[len(paper_cit_dict)//2:])\n",
    "\n",
    "with open(\"./datasets/dblp-aminer_v12/paper_cit_dict_p1.json\", 'w') as file:\n",
    "    json.dump(paper_cit_dict_p1, file)\n",
    "\n",
    "with open(\"./datasets/dblp-aminer_v12/paper_cit_dict_p2.json\", 'w') as file:\n",
    "    json.dump(paper_cit_dict_p2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=Elasticsearch([{'host':'localhost', 'port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=INDEX_NAME, ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'dblp_v12_v2'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0,        \n",
    "            \"similarity\": {\n",
    "                \"scripted_tfidf\": {\n",
    "                    \"type\": \"scripted\",\n",
    "                    \"script\": {\n",
    "                        \"source\": \"double tf = Math.sqrt(doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)) + 1.0; double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"similarity\": \"scripted_tfidf\"\n",
    "                    },\n",
    "                \"abstract\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"similarity\": \"scripted_tfidf\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "es.indices.create(index=INDEX_NAME, ignore=[400, 404], body=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_abstract(inverted_index):    \n",
    "    index = {}\n",
    "    for word, list_of_pos in inverted_index.items():\n",
    "        for pos in list_of_pos:\n",
    "            index[pos] = word\n",
    "    \n",
    "    abstract_list = []\n",
    "    for _, word in sorted(index.items(), key=lambda t: t[0]):\n",
    "        abstract_list.append(word)\n",
    "    \n",
    "    return \" \".join(abstract_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0e71ecc2124bab9a7f765cb1ebb30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4894081.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(DATASET_PATH) as file:\n",
    "    bulk = []\n",
    "    file.readline() # skip first line\n",
    "    \n",
    "    for _ in tqdm(range(N_RECORDS)): # n_papers\n",
    "        line = file.readline()\n",
    "        try:\n",
    "            paper = json.loads(line[1:])\n",
    "        except:\n",
    "            paper = json.loads(line)\n",
    "            \n",
    "        formatted_paper = {} \n",
    "        formatted_paper['paper_id'] = paper['id']\n",
    "        formatted_paper['title'] = paper['title']\n",
    "\n",
    "        if 'indexed_abstract' in paper:\n",
    "            indexed_abstract = paper.pop('indexed_abstract')\n",
    "            formatted_paper['abstract'] = reconstruct_abstract(indexed_abstract['InvertedIndex'])\n",
    "        else:\n",
    "            formatted_paper['abstract'] = ''\n",
    "            \n",
    "        if 'fos' in paper:\n",
    "            formatted_paper['fos'] = [fos['name'].lower() for fos in paper['fos']]\n",
    "        else:\n",
    "            formatted_paper['fos'] = []\n",
    "            \n",
    "        formatted_paper['doi'] = paper.pop('doi', '')\n",
    "        \n",
    "        linked_papers = []\n",
    "        if 'references' in paper:\n",
    "            linked_papers = paper['references']\n",
    "        if paper['id'] in paper_cit_dict:\n",
    "            linked_papers += paper_cit_dict[paper['id']]\n",
    "        formatted_paper['linked_papers'] = linked_papers\n",
    "        \n",
    "        # TODO add linked_papers\n",
    "            \n",
    "        bulk.append(formatted_paper)\n",
    "\n",
    "        if len(bulk) > 5000:\n",
    "            helpers.bulk(es, bulk, index=INDEX_NAME)\n",
    "            bulk = []\n",
    "                \n",
    "    if bulk:\n",
    "        helpers.bulk(es, bulk, index=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': '1594570479', 'timestamp': '16:14:39', 'count': '4894081'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.refresh(INDEX_NAME)\n",
    "es.cat.count(INDEX_NAME, params={\"format\": \"json\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
